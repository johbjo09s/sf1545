#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass scrartcl
\begin_preamble
\usepackage{listings}
\usepackage{xcolor}
\usepackage{matlab-prettifier}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{style=Matlab-editor}

\lstset{ %
  basicstyle=\footnotesize,        % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  commentstyle=\color{mygreen},    % comment style
  deletekeywords={...},            % if you want to delete keywords from the given language
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  language=Octave,                 % the language of the code
  otherkeywords={*,...},            % if you want to add more keywords to the set
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stringstyle=\color{mymauve},     % string literal style
}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman Adobe Garamond Pro
\font_sans Helvetica Neue
\font_typewriter Inconsolata
\font_math auto
\font_default_family default
\use_non_tex_fonts true
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize a4paper
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2cm
\topmargin 3cm
\rightmargin 2cm
\bottommargin 3cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
SF1545 - Lab 1
\end_layout

\begin_layout Subtitle
Applying Numerical Methods to Ramsey's 
\begin_inset Quotes eld
\end_inset

A Mathematical Theory Of Saving
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Author
Johan Björklund, u1480nqu, 
\begin_inset Flex URL
status open

\begin_layout Plain Layout

johbjo09@kth.se
\end_layout

\end_inset


\end_layout

\begin_layout Section
Minimize a series
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\min_{\alpha_{n}\in\mathbb{R}}\sum_{n=0}^{\infty}\left[\frac{Ũ\left(\tilde{\alpha}_{n}\right)}{f\left(X_{n}\right)-\tilde{\alpha}_{n}}\Delta X\right]
\]

\end_inset


\end_layout

\begin_layout Standard
To minimize the series, we need to take the partial derivate, and find critical
 points:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial}{\partial\tilde{\alpha}_{n}}\left(\sum_{n=0}^{\infty}\left[\frac{Ũ\left(\tilde{\alpha}_{n}\right)}{f\left(X_{n}\right)-\tilde{\alpha}_{n}}\Delta X\right]\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard
Expanding, we see:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial}{\partial\tilde{\alpha}_{n}}\left(\frac{Ũ\left(\tilde{\alpha}_{1}\right)}{f\left(X_{1}\right)-\tilde{\alpha}_{1}}+\frac{Ũ\left(\tilde{\alpha}_{2}\right)}{f\left(X_{2}\right)-\tilde{\alpha}_{2}}+\frac{Ũ\left(\tilde{\alpha}_{3}\right)}{f\left(X_{3}\right)-\tilde{\alpha}_{3}}+...+\frac{Ũ\left(\tilde{\alpha}_{n}\right)}{f\left(X_{n}\right)-\tilde{\alpha}_{n}}\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard
As the series expand, only one term in the series is dependent on the correspond
ing index of alpha.
 Taking the derivative with respect to a constant yields zero, so:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial}{\partial\tilde{\alpha}_{i}}\left(\frac{Ũ\left(\tilde{\alpha}_{j}\right)}{f\left(X_{j}\right)-\tilde{\alpha}_{j}}\right)=0
\]

\end_inset


\end_layout

\begin_layout Standard
The derivative of all other terms is zero.
 Therefore, we may say:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial}{\partial\tilde{\alpha}_{n}}\left(\sum_{n=0}^{\infty}\left[\frac{Ũ\left(\tilde{\alpha}_{n}\right)}{f\left(X_{n}\right)-\tilde{\alpha}_{n}}\Delta X\right]\right)=\sum_{n=0}^{\infty}\left[\frac{\partial}{\partial\tilde{\alpha}_{n}}\left(\frac{Ũ\left(\tilde{\alpha}_{n}\right)}{f\left(X_{n}\right)-\tilde{\alpha}_{n}}\right)\Delta X\right]
\]

\end_inset


\end_layout

\begin_layout Standard
To find the inner derivative, we apply the quotient rule:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial}{\partial\tilde{\alpha}_{n}}\left(\frac{Ũ\left(\tilde{\alpha}_{n}\right)}{f\left(X_{n}\right)-\tilde{\alpha}_{n}}\right)=\frac{Ũ^{\prime}\left(\tilde{\alpha}_{n}\right)\left(f\left(X_{n}\right)-\tilde{\alpha}_{n}\right)+Ũ\left(\tilde{\alpha}_{n}\right)}{\left(f\left(X_{n}\right)-\tilde{\alpha}_{n}\right)^{2}}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{Ũ^{\prime}\left(\tilde{\alpha}_{n}\right)\left(f\left(X_{n}\right)-\tilde{\alpha}_{n}\right)+Ũ\left(\tilde{\alpha}_{n}\right)}{\left(f\left(X_{n}\right)-\tilde{\alpha}_{n}\right)^{2}}=\frac{Ũ^{\prime}\left(\tilde{\alpha}_{n}\right)}{f\left(X_{n}\right)-\tilde{\alpha}_{n}}+\frac{Ũ\left(\tilde{\alpha}_{n}\right)}{\left(f\left(X_{n}\right)-\tilde{\alpha}_{n}\right)^{2}}=0
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{array}{ccc}
\frac{Ũ^{\prime}\left(\tilde{\alpha}_{n}\right)}{f\left(X_{n}\right)-\tilde{\alpha}_{n}}=\frac{-Ũ\left(\tilde{\alpha}_{n}\right)}{\left(f\left(X_{n}\right)-\tilde{\alpha}_{n}\right)^{2}} & \Longrightarrow & Ũ^{\prime}\left(\tilde{\alpha}_{n}\right)=\frac{-Ũ\left(\tilde{\alpha}_{n}\right)}{f\left(X_{n}\right)-\tilde{\alpha}_{n}}\end{array}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
f\left(X_{n}\right)-\tilde{\alpha}_{n}=\frac{-Ũ\left(\tilde{\alpha}_{n}\right)}{Ũ^{\prime}\left(\tilde{\alpha}_{n}\right)}
\]

\end_inset


\end_layout

\begin_layout Section
Fitting functions with least-squares
\end_layout

\begin_layout Standard
The given problem is to fit a second degree polynomial to certain data points
 using the method of least squares.
 The method finds the linear coefficients in a system of equations by factoring
 the coefficients of an equation into a vector, and arranging into a matrix
 equation.
 The system is so-called over-determined, as the number of equations exceed
 the number of coeffecients.
 Solving this system using matlab's 
\backslash
-operator is equivalent of minimizing the square norm of the residual 
\begin_inset Formula $\begin{Vmatrix}Ac-x\end{Vmatrix}$
\end_inset

 (hence 
\begin_inset Quotes eld
\end_inset

least squares
\begin_inset Quotes erd
\end_inset

), by setting the derivative with respect to the coefficients to zero, and
 then solving for 
\begin_inset Formula $c$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{array}{ccccc}
\frac{d}{dc}\begin{Vmatrix}Ac-x\end{Vmatrix}=2A^{T}\left(Ac-x\right)=0 & \Rightarrow & A^{T}\left(Ac-x\right)=0 & \Rightarrow & A^{T}Ac=A^{T}x\end{array}
\]

\end_inset


\end_layout

\begin_layout Subsection*
Notes on the code
\end_layout

\begin_layout Standard
In the function 
\family typewriter
computeLeastSquaresFit
\family default
 we make us of variable argument lists (
\family typewriter
varargin
\family default
 in matlab), which allows us to call the function with linear combinations
 of any functions.
 It returns two arrays; first the coefficients corresponding to the ordered
 input functions, and the residual.
 This is necessary for the function to be 
\emph on
testable
\emph default
 which is fundamental.
\end_layout

\begin_layout Subsection*
Results
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename lab1_b2.eps
	width 75text%

\end_inset


\end_layout

\begin_layout Standard
Firstly, we see that polynomials are unsuitable to model this data.
 We see from the residual plot that the two last points are the most important.
 The small value of b makes the function almost linear, and the least squared
 distance from these points is 
\begin_inset Quotes eld
\end_inset

between them
\begin_inset Quotes erd
\end_inset

, rather than crossing them.
 Sine the polynomial is always continous and 
\begin_inset Quotes eld
\end_inset

smooth
\begin_inset Quotes erd
\end_inset

, two successive data-points whose vector/line is almost orthogonal to the
 other data points will force the polynomial into 
\begin_inset Quotes eld
\end_inset

wide swings
\begin_inset Quotes erd
\end_inset

.
 Runges phenomenon is related, but also points out the wide swings outside
 of the data boundaries.
 Without the two last data points, the polynomial could have been a good
 fit, within the boundaries of the data.
\end_layout

\begin_layout Section
Fitting non-linear functions
\end_layout

\begin_layout Standard
Since the non-linear functions are not linear combinations, we can not directly
 use linear systems to solve for the constants.
 One way to transform exponential functions to linear systems is to use
 logarithms.
 As a solution, this places narrow restrictions on the functions and the
 code is not reusable.
\end_layout

\begin_layout Subsection*
Gauss-Newton method
\end_layout

\begin_layout Standard
Our solution is to use Gauss-Newton, which achieves linearisation through
 a jacobian matrix.
 The advantage over logarithms is that our code can be used for any function
 for which we can find a jacobian.
 If we can not find a jacobian analytically, we could use approximations.
 This allows us to test several candidate functions with minimal manual
 calculation.
\end_layout

\begin_layout Standard
Gauss-Newton is a type of fixed point iterative method.
 By linearisation, each equation in the system corresponds geometrically
 to a plane (though number of dimensions may vary.) At each iteration, we
 exploit the linearisation to solve the system for the coefficients using
 matlab's 
\backslash
-operator, and update the coefficients with the residual, until the residual
 is smaller than a set tolerance.
\end_layout

\begin_layout Subsection*
Notes on the code
\end_layout

\begin_layout Standard
We make use of matlab's cell array as a container to place functions, the
 partial derivatives, so we can factor the computation of jacobians.
 Watch for 
\family typewriter
{}-brackets
\family default
 in the code.
\end_layout

\begin_layout Standard
Rearrange:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{1}{\tilde{U}\left(\alpha\right)}=\frac{1}{8}+\frac{a}{\alpha}\Longrightarrow\tilde{U}(\alpha)=\frac{8\alpha}{\alpha+8a}
\]

\end_inset


\end_layout

\begin_layout Standard
Find partial derivatives:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial\tilde{U}}{\partial a}=8\alpha\frac{-8}{\left(\alpha+8a\right)^{2}}
\]

\end_inset


\end_layout

\begin_layout Subsection*
Results
\end_layout

\begin_layout Standard
Tolerance is set to 
\begin_inset Formula $10^{-6}$
\end_inset

.
 Starting values are found by experimentation.
 Blue crosses are residuals.
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename lab1_b3_1.eps
	width 75text%

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename lab1_b3_2.eps
	width 75text%

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename lab1_b3_polynomial.eps
	width 65text%

\end_inset


\end_layout

\begin_layout Subsection*
Analysis
\end_layout

\begin_layout Standard
The exponential function 
\begin_inset Formula $U(\tilde{\alpha})=8-a\tilde{\alpha}^{b}$
\end_inset

 is sensitive to variations in the constant 
\begin_inset Formula $b$
\end_inset

 and very sensitive to starting values, sometimes diverging with positive
 values for 
\begin_inset Formula $b$
\end_inset

.
 In this example the residual is smaller, but seems to grow.
 If accuracy close to zero is important, the exponential function is favourable.
\end_layout

\begin_layout Standard
For the polynomial, the residual is exactly zero (from the definition of
 polynomial fitting) but it is a bad choice, crossing into negative asymptically
 diverging to infinity.
\end_layout

\begin_layout Standard
The quotient function 
\begin_inset Formula $\frac{8\alpha}{\alpha+8a}$
\end_inset

 converges faster than the exponential, is less sensitive to small varitions,
 and is less sensitive to starting values, and might be faster to compute.
 All of these factors might have more relevance in real-world applications
 (for example realtime systems with realtime data, possibly with limited
 computational resources) than in lab-environments using scientific software.
 We see from the plot that the residual is largest close to zero, which
 might be acceptable under circumstances.
 We could attempt to improve the fit, for example by modeling the residual
 and adding terms that cancel the residual.
\end_layout

\begin_layout Standard
The choice of modeling function depends on application, and without knowing
 test cases it is meaningless to decide.
\end_layout

\begin_layout Standard
In Ramsey's model, accuracy as 
\begin_inset Formula $\alpha$
\end_inset

 grows is more important, so the quotient is probably favourable over the
 exponential.
\end_layout

\begin_layout Subsection*
Maximum relative error
\end_layout

\begin_layout Standard
Find the maximum relative error in 
\begin_inset Formula $\alpha$
\end_inset

: 
\begin_inset Formula $\frac{\Delta\alpha}{\alpha}$
\end_inset

, given relative errors in 
\begin_inset Formula $U$
\end_inset

 and 
\begin_inset Formula $U^{\prime}$
\end_inset

.
 First, rearrange our equation:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
f\left(X_{n}\right)-\tilde{\alpha}_{n}=\frac{-Ũ\left(\tilde{\alpha}_{n}\right)}{Ũ^{\prime}\left(\tilde{\alpha}_{n}\right)}\Longrightarrow\alpha_{n}=f\left(X\right)+\frac{U}{U^{\text{\prime}}}
\]

\end_inset


\end_layout

\begin_layout Standard
From the definition of partial derivatives, we remember that linearisation
 means 
\begin_inset Quotes eld
\end_inset

variation in 
\begin_inset Formula $z$
\end_inset

 depending on variation of 
\begin_inset Formula $x$
\end_inset

 and 
\begin_inset Formula $y$
\end_inset


\begin_inset Quotes erd
\end_inset

 when 
\begin_inset Formula $z=f(x,y)$
\end_inset

 - this would also be the equation of a tangent plane to 
\begin_inset Formula $z=f(x,y)$
\end_inset

.
 We recognize our problem of finding dependent errors as being similar:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\Delta\alpha=\frac{\partial\alpha}{\partial U}\Delta U+\frac{\partial\alpha}{\partial U^{\prime}}\Delta U^{\prime}
\]

\end_inset


\end_layout

\begin_layout Standard
After finding partial derivatives, and the given relative errors:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{array}{ccccc}
\frac{\partial\alpha}{\partial U}=\frac{1}{U^{\prime}} & \qquad\frac{\partial\alpha}{\partial U^{\prime}}=-\frac{U}{\left(U^{\prime}\right)^{2}} &  &  & \frac{\Delta U}{U}=\frac{\Delta U^{\prime}}{U^{\prime}}=\pm\frac{1}{10}\end{array}
\]

\end_inset


\end_layout

\begin_layout Standard
the problem of solving for 
\begin_inset Formula $\frac{\Delta\alpha}{\alpha}$
\end_inset

 is now a matter of algebra:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{array}{crcclc}
\Delta\alpha=\frac{1}{U^{\prime}}\Delta U-\frac{U}{\left(U^{\prime}\right)^{2}}\Delta U^{\prime} & \quad & \Delta\alpha & = & \frac{1}{U^{\prime}}\left(\Delta U-\frac{U}{U^{\prime}}\Delta U^{\prime}\right)\end{array}
\]

\end_inset


\end_layout

\begin_layout Standard
The maximum error occurs when 
\begin_inset Formula $f\left(X\right)=0$
\end_inset

 in the denominator:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{array}{lcl}
\frac{\Delta\alpha}{\alpha}=\frac{1}{f\left(X\right)+\frac{U}{U^{\text{\prime}}}}\frac{1}{U^{\prime}}\left(\Delta U-\frac{U}{U^{\prime}}\Delta U^{\prime}\right) & \Rightarrow & \frac{\Delta\alpha}{\alpha}=\frac{1}{\frac{U}{U^{\text{\prime}}}}\frac{1}{U^{\prime}}\left(\Delta U-\frac{U}{U^{\prime}}\Delta U^{\prime}\right)\end{array}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{array}{lcl}
\frac{\Delta\alpha}{\alpha}=\frac{U^{\prime}}{U}\frac{1}{U^{\prime}}\left(\Delta U-\frac{U}{U^{\prime}}\Delta U^{\prime}\right) & \Rightarrow & \frac{\Delta\alpha}{\alpha}=\frac{\Delta U}{U}-\frac{1}{U^{\prime}}\Delta U^{\prime}\end{array}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{array}{lcl}
\frac{\Delta\alpha}{\alpha}=\frac{\Delta U}{U}-\frac{\Delta U^{\prime}}{U^{\prime}} & \Rightarrow & \frac{\Delta\alpha}{\alpha}=\pm\frac{1}{10}\mp\frac{1}{10}=\pm\frac{1}{5}\end{array}
\]

\end_inset


\end_layout

\begin_layout Standard
Maximum absolute relative error is 
\begin_inset Formula $\frac{2}{10}=\frac{1}{5}$
\end_inset

.
\end_layout

\begin_layout Section
Constrained optimization with lagrange multipliers
\end_layout

\begin_layout Standard
The given problem is to find the optimum level of salaries (consumption)
 and re-investments (savings) in a company.
 This is modeled as the maximisation problem:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\max_{\alpha\in\mathbb{R^{N}}}\int_{0}^{T}U\left(\alpha(t)\right)dt+g\left(X(T)\right)
\]

\end_inset


\end_layout

\begin_layout Standard
subject to the constraint:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{array}{ccc}
\frac{d}{dt}X(t) & = & f\left(X(t)\right)-\alpha(t)\end{array}
\]

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $X(t)$
\end_inset

 is our production funtion.
\end_layout

\begin_layout Standard
The strategy is to convert this optimization problem into a linear system
 of equations that can be solved using familiar methods.
 
\end_layout

\begin_layout Standard
We formulate the problem into a lagrange function:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathcal{L}\left(X,\alpha,\lambda\right)=\int_{0}^{T}U\left(\alpha\right)dt+g\left(X\right)-\lambda\left(f\left(X(t)\right)-\alpha(t)-\frac{dX}{dt}(t)\right)
\]

\end_inset


\end_layout

\begin_layout Standard
The principle of linearisation allows us to use linear systems to solve
 this problem (normal lagrange multiplier method).
 However, we see the difficulty in proceeding to find the gradient of 
\begin_inset Formula $\mathcal{L}$
\end_inset

 and finding roots, and consider the suggestion that a numerical approach
 might be easier.
\end_layout

\begin_layout Paragraph*
Euler approximation
\end_layout

\begin_layout Standard
Our solution to the differential in the constraint condition is to use euler
 approximation, and approximating the integral with piecewise constant functions.
 Occurences of 
\begin_inset Formula $dt$
\end_inset

 transforms to 
\begin_inset Formula $\Delta t$
\end_inset

, the integral transforms into a riemann-sum, the constraint turns into
 an euler approximation:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathcal{L}\left(X,\alpha,\lambda\right)=\sum_{n=0}^{N-1}U\left(\alpha_{n}\right)\Delta t+g\left(X_{n}\right)-\sum_{n=0}^{N-1}\lambda_{n+1}\left(X_{n+1}-X_{n}-\Delta t\left(f(X_{n})-\alpha_{n}\right)\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Setting the gradient to zero 
\begin_inset Formula $\nabla\mathcal{L}=<0,0,0>$
\end_inset

 and rearranging, the lagrange system becomes:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{array}{rll}
\lambda_{n+1} & = & U^{\prime}\left(\alpha_{n}\right)\\
\lambda_{n} & = & \lambda_{n+1}+\Delta t\: f^{\prime}\left(X_{n}\right)\:\lambda_{n+1}\\
X_{n+1} & = & X_{n}+\Delta t\left(f(X_{n})-\alpha_{n}\right)
\end{array}
\]

\end_inset


\end_layout

\begin_layout Standard
Since this gives us 
\begin_inset Formula $U^{\prime}=\lambda_{n+1}$
\end_inset

, we can solve for 
\begin_inset Formula $\alpha$
\end_inset

 as function of 
\begin_inset Formula $\lambda$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{array}{rcccccccc}
U\left(\alpha\right) & = & -\frac{3}{2}\alpha^{\frac{-2}{3}}\\
U^{\prime}(\alpha_{n}) & = & \frac{d}{d\alpha_{n}}\left(-\frac{3}{2}\alpha_{n}^{\frac{-2}{3}}\right) & = & \alpha_{n}^{\frac{-5}{3}} &  &  & = & \lambda_{n+1}\\
 &  &  &  & \left(\alpha_{n}^{\frac{-5}{3}}\right)^{\frac{-3}{5}} & = & \alpha_{n} & = & \left(\lambda_{n+1}\right)^{\frac{-3}{5}}
\end{array}
\]

\end_inset


\end_layout

\begin_layout Standard
The numerical system is larger, with one equation for each time step.
 We find 
\begin_inset Formula $X(t),\:\lambda(t),\:\alpha(t)$
\end_inset

 as arrays of numbers through iterations.
\end_layout

\begin_layout Subsection*
Results and analysis
\end_layout

\begin_layout Standard
Results are presented in these graphs.
 
\begin_inset Formula $\alpha(t)$
\end_inset

 is represented by black plots 
\begin_inset Formula $\lambda(t)$
\end_inset

 is represented by magenta plots.
 Dotted lines are iterations, the solid line is the final result after a
 tolerance of 
\begin_inset Formula $10^{-4}$
\end_inset

 is achieved.
\end_layout

\begin_layout Standard
\noindent
\align left
\begin_inset Graphics
	filename lab1_b4_1.eps
	width 55text%

\end_inset


\begin_inset Graphics
	filename lab1_b4_2.eps
	width 55text%

\end_inset


\end_layout

\begin_layout Standard
\noindent
\align center
\begin_inset Graphics
	filename lab1_b4_3.eps
	width 55text%

\end_inset


\end_layout

\begin_layout Subsection*
Interpretation of the lagrange multipliers
\end_layout

\begin_layout Standard
What is the meaning of the lagrange multipliers in this case? Because they
 multiply reinvestments/savings, they represent the significance of reinvestment
s at time 
\begin_inset Formula $t$
\end_inset

 with respect to long-term consumption.
 Further, we see from the lagrangian system: 
\begin_inset Formula $U^{\prime}=\lambda_{n+1}$
\end_inset

, which can be interpreted directly as marginal utility of consumption.
\end_layout

\begin_layout Standard
\begin_inset Formula $\lambda(t)$
\end_inset

 might be interpreted as the constraint on consumption at time 
\begin_inset Formula $t$
\end_inset

 necessary for maximum total consumption, over time.
 We might also interpret it as the magnitude of 
\begin_inset Quotes eld
\end_inset

the force
\begin_inset Quotes erd
\end_inset

 that restricts consumption and increases saving: analogous to the function
 of interest rates.
\end_layout

\begin_layout Standard
This is supported by the graphs, which show that the multipliers start high
 and converge.
\end_layout

\begin_layout Subsection*
Attempts with cyclical growth
\end_layout

\begin_layout Standard
As an experiment, we test a production function 
\begin_inset Formula $f(X)$
\end_inset

 with a periodic term:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\begin{array}{ccc}
f(X)=x^{c+a\sin(\pi\omega x)} & \qquad & \frac{df}{dx}=f(X)\left(a\pi\omega\cos(\pi\omega x)\ln x+\frac{c+a\sin(\pi\omega x)}{x}\right)\end{array}
\]

\end_inset


\end_layout

\begin_layout Standard
We're looking for patterns and convergence; and keeping in mind that 
\begin_inset Formula $\lambda(t)$
\end_inset

 is vaguely analogous to interest rates in economies.
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename lab1_b4_cyclical1.eps
	width 75text%

\end_inset


\end_layout

\begin_layout Standard
We see that solutions stay within bounds around the related linear solution,
 with no clear convergence within the bounds.
\end_layout

\begin_layout Standard

\emph on
cyclical2:
\emph default
 With a small growth constant c and strong imprint from the periodic term
 via the amplitude, the bounds are wide and we see no convergence within
 the bounds.
 No constraint seems to be able to create a convergent solution.
 Overall, the solutions still converge.
\end_layout

\begin_layout Standard
\noindent
\align left
\begin_inset Graphics
	filename lab1_b4_cyclical2.eps
	width 50text%

\end_inset


\begin_inset Graphics
	filename lab1_b4_cyclical3.eps
	width 50text%

\end_inset


\end_layout

\begin_layout Standard
Many attempts and variations showed similar patterns.
 It suggests that under more realistic circumstances the problem is less
 deterministic.
 We see that 
\begin_inset Formula $\lambda(t)$
\end_inset

 seems to converge to more linear shapes; suggesting that over-corrections
 lead to less optimal solutions.
\end_layout

\begin_layout Standard

\emph on
cyclical4:
\emph default
 Increasing frequency changes the shape, and sometimes allows for clear
 convergence:
\end_layout

\begin_layout Standard
\noindent
\align left
\begin_inset Graphics
	filename lab1_b4_cyclical4.eps
	width 50text%

\end_inset


\begin_inset Graphics
	filename lab1_b4_cyclical6.eps
	width 50text%

\end_inset


\end_layout

\begin_layout Standard

\emph on
cyclical6:
\emph default
 Negative growth gives an interesting example; starting with high decreasing
 consumption and low investment, and eventually inverting.
 We see many possible solutions with early invertions, but solutions with
 later invertions are more clustered:
\end_layout

\begin_layout Section
Error sources
\end_layout

\begin_layout Subsubsection*
Assumptions about physical conditions
\end_layout

\begin_layout Standard
To what degree does Ramsey's mathematical model correspond to physical reality?
 Ramsey makes assumptions about production as function of capital (disregarding
 the role of human creative input), and enjoyment/utility as a function
 of production (disregarding misallocations), and labour as 
\begin_inset Quotes eld
\end_inset

disutility
\begin_inset Quotes erd
\end_inset

 (disregarding work a meaningful).
 Applying a model like Ramsey's requires careful understanding of the assumption
s.
\end_layout

\begin_layout Standard
In other applications, it might be less obvious how the mathematical model
 misrepresents physical reality, even if calculated without errors.
 A book (Peter Pohl) gives the example 
\begin_inset Quotes eld
\end_inset

a point-mass, pendulating with infinitely small movements on a massless
 string
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Paragraph*
Input data
\end_layout

\begin_layout Standard
In our example, input data was picked from Ramsey's original paper, and
 likely has little connection to present economic conditions.
\end_layout

\begin_layout Paragraph*
Truncation
\end_layout

\begin_layout Standard
Truncation is the error resulting from the interrupted limit.
 For example; in euler and trapezoid methods, since 
\begin_inset Formula $\Delta t$
\end_inset

 is fixed an does not approach zero (as in the analytical solutions) each
 iteration will accumulate an error.
 This will happen regardless of convergence characteristics of the algorithm
 (both forward and implicit euler).
\end_layout

\begin_layout Paragraph*
Euler and trapezoid
\end_layout

\begin_layout Standard
Algorithms such as euler approximation cause mathematical errors relative
 to analytical solutions.
 Forward euler, for example, will diverge.
 While this would not happen if somehow implemented numerically with true
 infinitesimals and limits, the truncation error is particularily worse
 in certain algorithms.
 The integration approximation in problem 4, has error 
\begin_inset Formula $O\left(\frac{1}{n}\right)$
\end_inset

.
 Trapezoid has an error on the order of 
\begin_inset Formula $O\left(\frac{1}{n^{2}}\right)$
\end_inset

.
 These can be derived through taylor approximation.
\end_layout

\begin_layout Standard
Truncation errors can be minimized by reducing stepsizes; however, precision
 errors grow with smaller stepsizes; and as number of iterations grow, all
 errors can compound.
\end_layout

\begin_layout Paragraph*
Precision
\end_layout

\begin_layout Standard
Cancellation errors occur as one number is subtracted from another close
 number.
 The difference that is smaller than precision is the error.
 Since the resulting number is small, the relative error might be large.
\end_layout

\begin_layout Paragraph*
Comparison
\end_layout

\begin_layout Standard
The biggest source of error in our lagrange system is likely truncation
 from large stepsizes.
 Meanwhile, precision and accuracy is probably adequate will compared to
 reliability of the input data.
\end_layout

\begin_layout Paragraph*
Experimental error analysis and condition numbers
\end_layout

\begin_layout Standard
We test the optimization method from section 4, by adding errors 
\begin_inset Formula $erra$
\end_inset

 and 
\begin_inset Formula $errb$
\end_inset

 to the coefficients of the production function 
\begin_inset Formula $aX+bX^{2}$
\end_inset

.
 The red/dashed line is the 
\begin_inset Formula $\alpha$
\end_inset

-plot corresponding to the error.
 We get a visual impression of the 
\begin_inset Quotes eld
\end_inset

condition
\begin_inset Quotes erd
\end_inset

 of the optimization algorithm.
 We see condition numbers 
\begin_inset Formula $\left(\frac{err_{out}}{err_{in}}\right)$
\end_inset

, at worst, close to one.
\end_layout

\begin_layout Standard
\noindent
\align left
\begin_inset Graphics
	filename lab1_b4_err1.eps
	width 50text%

\end_inset


\begin_inset Graphics
	filename lab1_b4_err2.eps
	width 50text%

\end_inset


\end_layout

\begin_layout Standard
\noindent
\align left
\begin_inset Graphics
	filename lab1_b4_err3.eps
	width 50text%

\end_inset


\begin_inset Graphics
	filename lab1_b4_err4.eps
	width 50text%

\end_inset


\end_layout

\begin_layout Quotation
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section*
Code listings
\end_layout

\begin_layout Standard
All graphs were produced by the code listed below.
 All code was run with octave.
\end_layout

\begin_layout Section*
lab1_b2.m
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstinputlisting{lab1_b2.m}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section*
lab1_b3.m
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstinputlisting{lab1_b3.m}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section*
lab1_b4.m
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
lstinputlisting{lab1_b4.m}
\end_layout

\end_inset


\end_layout

\end_body
\end_document
